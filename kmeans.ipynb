{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import Word2Vec\n",
    "from pyspark.sql.types import StructType\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup link to s3\n",
    "import urllib\n",
    "ACCESS_KEY = \"AKIAJB4ROWFQHV5ALGBA\"\n",
    "SECRET_KEY = \"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\"\n",
    "ENCODED_SECRET_KEY = urllib.quote(SECRET_KEY, \"\")\n",
    "AWS_BUCKET_NAME = \"github-spark\"\n",
    "MOUNT_NAME = \"github-spark\"\n",
    "dbutils.fs.mount(\"s3n://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull in files from s3\n",
    "py_files = '/mnt/github-spark/data/py_contents.txt'\n",
    "rst_files = '/mnt/github-spark/data/rst_contents.txt'\n",
    "md_files = '/mnt/github-spark/data/md_contents.txt'\n",
    "\n",
    "files = [py_files, rst_files]\n",
    "\n",
    "# pull in file from s3 to textfile\n",
    "s3_input = sc.textFile('\\n'.join(files)).map(lambda row: row.split(\" \"))\n",
    "#inp = sc.textFile(\"/mnt/github-spark/{0}\".format(s3_input)).map(lambda row: row.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = Word2Vec().setVectorSize(10)\n",
    "model = word2vec.fit(s3_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentenceData = sqlContext.createDataFrame(s3_input)\n",
    "sentenceData.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "sentenceData = sqlContext.createDataFrame(s3_input, [\"sentence\"])\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(sentenceData)\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "#for features_label in rescaledData.select(\"features\", \"label\").take(3):\n",
    "#    print(features_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "kmeans",
  "notebookId": 321
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
