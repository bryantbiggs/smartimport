{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "import tinys3\n",
    "import json\n",
    "import pandas as pd\n",
    "from bson.json_util import dumps\n",
    "from pymongo import MongoClient\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pw_file = 'credentials/mongo_pw.txt'\n",
    "if os.path.exists(pw_file): \n",
    "    with open(pw_file, 'r') as f:\n",
    "        pub_ip, mongo_usr, mongo_usr_pw = f.readline().strip().split(', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to ec2 mongo client\n",
    "client = MongoClient('{0}:27017'.format(pub_ip))\n",
    "\n",
    "# get reference to  github_db\n",
    "db = client['github_db']\n",
    "\n",
    "# authenticate user for database\n",
    "db.authenticate(mongo_usr, mongo_usr_pw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show MongoDB collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_collections(col_type='all'):\n",
    "    '''\n",
    "    IN: None\n",
    "    RETURN: Printed output of collections and collection counts\n",
    "    '''\n",
    "    for name in sorted(db.collection_names()):\n",
    "        if col_type == 'backup':\n",
    "            if 'backup' in name:\n",
    "                print('Documents in \\\"{0}\\\" collection: {1}'.format(name, db[name].count()))\n",
    "        elif col_type == 'original':\n",
    "            if 'backup' not in name:\n",
    "                print('Documents in \\\"{0}\\\" collection: {1}'.format(name, db[name].count()))\n",
    "        else:\n",
    "            print('Documents in \\\"{0}\\\" collection: {1}'.format(name, db[name].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents in \"git_repos_contributors\" collection: 3074\n",
      "Documents in \"git_repos_contributors_backup\" collection: 3030\n",
      "Documents in \"git_repos_docs\" collection: 146833\n",
      "Documents in \"git_repos_docs_backup\" collection: 146685\n",
      "Documents in \"git_repos_meta\" collection: 3073\n",
      "Documents in \"git_repos_meta_backup\" collection: 3029\n",
      "Documents in \"git_repos_subscribers\" collection: 3074\n",
      "Documents in \"git_repos_subscribers_backup\" collection: 3030\n",
      "Documents in \"git_users_followers\" collection: 1398\n",
      "Documents in \"git_users_followers_backup\" collection: 1364\n",
      "Documents in \"git_users_following\" collection: 1398\n",
      "Documents in \"git_users_following_backup\" collection: 1364\n",
      "Documents in \"git_users_meta\" collection: 1397\n",
      "Documents in \"git_users_meta_backup\" collection: 1363\n"
     ]
    }
   ],
   "source": [
    "show_collections('all')\n",
    "# db.drop_collection('git_repos_contributors_backup')\n",
    "# db.drop_collection('git_repos_docs_backup')\n",
    "# db.drop_collection('git_repos_meta_backup')\n",
    "# db.drop_collection('git_repos_subscribers_backup')\n",
    "\n",
    "# db.drop_collection('git_users_followers_backup')\n",
    "# db.drop_collection('git_users_following_backup')\n",
    "# db.drop_collection('git_users_meta_backup')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def backup(db):\n",
    "    original_names = [x for x in db.collection_names() if 'backup' not in x]\n",
    "    \n",
    "    for name in original_names:\n",
    "        cursor = db[name].find()\n",
    "        try:\n",
    "            db['{0}_backup'.format(name)].insert_many(list(cursor))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %time backup(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter based on file extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_filetypes(db, col, _filter='all'):\n",
    "\n",
    "    if _filter != 'all':\n",
    "        db_new = db[col].find({'file_extension': re.compile(_filter, re.IGNORECASE)}, \n",
    "                              {'_id': False, 'file_name':1, 'file_extension':1, 'file_contents':1, 'repo_name':1, \n",
    "                               'repo_id':1, 'repo_fullname':1, 'repo_owner_login':1})\n",
    "    else:\n",
    "        db_new = db[col].find({}, {'_id': False, 'file_name':1, 'file_extension':1, 'file_contents':1, 'repo_name':1, \n",
    "                               'repo_id':1, 'repo_fullname':1, 'repo_owner_login':1})\n",
    "    \n",
    "    return db_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean file contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_py(doc):\n",
    "    string = doc['file_contents']\n",
    "    string = re.sub(re.compile('\"\"\".*?\"\"\"',re.DOTALL) ,\"\" ,string)\n",
    "    string = re.sub(re.compile('#.*?\\n' ) ,' ' ,string)\n",
    "    string = re.sub(re.compile('\".*?\"',re.DOTALL ) ,\"\" ,string)\n",
    "    string = re.sub(re.compile(\"'.*?'\",re.DOTALL ) ,\"\" ,string)\n",
    "    string = string.replace('\\\\n', ' ')\n",
    "    string = string.replace('\\\\t', ' ')\n",
    "    string = re.sub('\\\\s+', ' ', string).strip()\n",
    "    \n",
    "    chrs = \"[]{}\"\n",
    "    for ch in chrs:\n",
    "        string = string.replace(ch, ' ')\n",
    "        \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_md(doc):\n",
    "    x = doc['file_contents'].replace('\\\\n', ' ')\n",
    "    x = x.replace('\\t', ' ')\n",
    "    x = x.replace(\"\\'\", ' ')\n",
    "    x = x.replace('\"', ' ')\n",
    "    \n",
    "    # remove hyperlinks\n",
    "    reg = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    x = re.sub(reg, ' ', x).strip()\n",
    "\n",
    "    x = re.sub(re.compile('<.*?>',re.DOTALL ) ,\"\" ,x)\n",
    "    \n",
    "    x = re.sub('[^0-9a-zA-Z]+', ' ', x)\n",
    "    \n",
    "    chrs = \"0123456789\"\n",
    "    for ch in chrs:\n",
    "        x = x.replace(ch, ' ')\n",
    "        \n",
    "    x = re.sub('\\\\s+', ' ', x).strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_rst(doc):\n",
    "    x = doc['file_contents'].replace('\\\\n', ' ')\n",
    "    x = x.replace('\\t', ' ')\n",
    "    x = x.replace(\"\\'\", ' ')\n",
    "    x = x.replace('\"', ' ')\n",
    "    \n",
    "    # remove hyperlinks\n",
    "    reg = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    x = re.sub(reg, ' ', x).strip()\n",
    "\n",
    "    x = re.sub(re.compile('<.*?>',re.DOTALL ) ,\"\" ,x)\n",
    "    \n",
    "    x = re.sub('[^a-zA-Z]+', ' ', x)\n",
    "    \n",
    "    chrs = \"-`*+=~\"\n",
    "    for ch in chrs:\n",
    "        x = x.replace(ch, ' ')\n",
    "        \n",
    "    x = re.sub('\\\\s+', ' ', x).strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_script_content(db):\n",
    "    col = db['git_repos_docs_backup']\n",
    "    cursor = col.find()\n",
    "\n",
    "    for doc in cursor:\n",
    "        ext = doc['file_extension']\n",
    "#         if ext == 'md':\n",
    "#             col.update_one(\n",
    "#                     {'doc_name' : doc['doc_name'], 'file_extension': 'md'}, \n",
    "#                     {'$set':{\n",
    "#                             'file_contents': clean_md(doc),}\n",
    "#                         }, \n",
    "#                     upsert=False)\n",
    "#         elif ext == 'rst':\n",
    "#             col.update_one(\n",
    "#                     {'doc_name' : doc['doc_name'], 'file_extension': 'rst'}, \n",
    "#                     {'$set':{\n",
    "#                             'file_contents': clean_rst(doc),}\n",
    "#                         }, \n",
    "#                     upsert=False)\n",
    "        if ext =='SKIP':\n",
    "            pass\n",
    "        else:\n",
    "            col.update_one(\n",
    "                    {'doc_name' : doc['doc_name']}, \n",
    "                    {'$set':{\n",
    "                            'file_contents': clean_py(doc),}\n",
    "                        }, \n",
    "                    upsert=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 56s, sys: 56.1 s, total: 3min 52s\n",
      "Wall time: 3h 29min 11s\n"
     ]
    }
   ],
   "source": [
    "%time clean_script_content(db)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "cursor = db['git_repos_docs_backup'].find({'file_extension':'py'})\n",
    "cursor[1]['file_contents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert rst READMES to md extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mark_readmes_md(db):\n",
    "    col = db['git_repos_docs_backup']\n",
    "\n",
    "    readme_files = col.find({'file_name' : {'$regex' : '.*README.*'}, 'file_extension' : 'rst'})\n",
    "\n",
    "    for doc in readme_files:\n",
    "            col.update_one(\n",
    "                    {'doc_name' : doc['doc_name']}, \n",
    "                    {'$set':{\n",
    "                            'file_extension': 'md',}\n",
    "                        }, \n",
    "                    upsert=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove short entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_short_contents(min_len=50, db=db):\n",
    "    py_ct = 0\n",
    "    rst_ct = 0\n",
    "    md_ct = 0\n",
    "    a = db['git_repos_docs_backup'].find()\n",
    "\n",
    "    for i in a:\n",
    "        if len(i['file_contents']) < min_len:\n",
    "            if i['file_extension'] =='py':\n",
    "                py_ct += 1\n",
    "            if i['file_extension'] =='rst':\n",
    "                rst_ct += 1\n",
    "            if i['file_extension'] =='md':\n",
    "                md_ct += 1\n",
    "            db['git_repos_docs_backup'].delete_one({'_id': i['_id']})\n",
    "    print('{0} .py records deleted'.format(py_ct))\n",
    "    print('{0} .rst records deleted'.format(rst_ct))\n",
    "    print('{0} .md records deleted'.format(md_ct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2882 .py records deleted\n",
      "543 .rst records deleted\n",
      "427 .md records deleted\n",
      "CPU times: user 11.7 s, sys: 10.3 s, total: 22 s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%time remove_short_contents(min_len=50, db=db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def s3_upload(file):\n",
    "    try:\n",
    "        with open('credentials/aws.csv', 'r') as infile:\n",
    "            _ = infile.readline()\n",
    "            username, access_key, secret_key = infile.readline().replace('\"', '').split(',')\n",
    "\n",
    "        conn = tinys3.Connection(access_key, secret_key, tls=True)\n",
    "\n",
    "        with open(file,'rb') as f:\n",
    "            conn.upload(file,f,'github-spark')\n",
    "    except:\n",
    "        print('Upload failed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert queries into json files and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word2vec_content_json(filename, ext, db=db):\n",
    "    \n",
    "    cursor = db['git_repos_docs_backup'].find({'file_extension' : {'$regex' : '.*{0}.*'.format(ext)}},\n",
    "                                             {'_id': False, 'file_contents':1})\n",
    "\n",
    "    cursor = dumps(cursor)\n",
    "    cur = cursor\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    with open(filename, 'a') as of:\n",
    "        of.write(cur)\n",
    "    \n",
    "    # upload to s3\n",
    "    s3_upload(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.1 s, sys: 9.73 s, total: 27.8 s\n",
      "Wall time: 1min 6s\n",
      "CPU times: user 2.77 s, sys: 1.6 s, total: 4.37 s\n",
      "Wall time: 9.69 s\n",
      "CPU times: user 1.33 s, sys: 645 ms, total: 1.98 s\n",
      "Wall time: 6.28 s\n"
     ]
    }
   ],
   "source": [
    "%time word2vec_content_json('data/py_contents.json', 'py')\n",
    "%time word2vec_content_json('data/rst_contents.json', 'rst')\n",
    "%time word2vec_content_json('data/md_contents.json', 'md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pymongo to List"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cursor = db['git_repos_docs_backup'].find({'file_extension' : {'$regex' : '.*{0}.*'.format('md')}},\n",
    "                                             {'_id': False, 'file_contents':1})\n",
    "temp = []\n",
    "for i in cursor[:2]:\n",
    "    temp.append(i['file_contents'])\n",
    "\n",
    "lst = [i['file_contents'] for i in cursor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pymongo_list(filename, ext, db=db):\n",
    "    \n",
    "    cursor = db['git_repos_docs_backup'].find({'file_extension' : {'$regex' : '.*{0}.*'.format(ext)}},\n",
    "                                             {'_id': False, 'file_contents':1})\n",
    "\n",
    "    lst = [i['file_contents'] for i in cursor]\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    with open(filename, 'w') as of:\n",
    "        of.write('\\n'.join(lst))\n",
    "    \n",
    "    # upload to s3\n",
    "    s3_upload(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 s, sys: 18.9 s, total: 38.9 s\n",
      "Wall time: 2min 9s\n",
      "CPU times: user 2.53 s, sys: 2.38 s, total: 4.91 s\n",
      "Wall time: 16.7 s\n",
      "CPU times: user 1.12 s, sys: 1.06 s, total: 2.18 s\n",
      "Wall time: 8.04 s\n"
     ]
    }
   ],
   "source": [
    "%time pymongo_list('data/py_contents.txt', 'py')\n",
    "%time pymongo_list('data/rst_contents.txt', 'rst')\n",
    "%time pymongo_list('data/md_contents.txt', 'md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number documents check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mongo_count(db):\n",
    "    vals = []\n",
    "    files = ['py_contents', 'rst_contents', 'md_contents']\n",
    "    for file in files:\n",
    "        ext = file.split('_')[0]\n",
    "        val = db['git_repos_docs_backup'].count({'file_extension' : {'$regex' : '.*{0}.*'.format(ext)}})\n",
    "        vals.append(val)\n",
    "        print('Mongo {0} count: {1}'.format(ext, val))\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def file_count(db):\n",
    "    vals = []\n",
    "    files = ['py_contents', 'rst_contents', 'md_contents']\n",
    "    for file in files:\n",
    "        with open('data/{0}.json'.format(file), 'r') as f:\n",
    "            data = json.load(f)\n",
    "        val = len(data)\n",
    "        vals.append(val)\n",
    "        print('File {0} count: {1}'.format(file.split('_')[0], val))\n",
    "        data = None\n",
    "    return vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def file_loss_check(db):\n",
    "    assert mongo_count(db) == file_count(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mongo py count: 114828\n",
      "Mongo rst count: 19374\n",
      "Mongo md count: 8495\n",
      "File py count: 114828\n",
      "File rst count: 19374\n",
      "File md count: 8495\n"
     ]
    }
   ],
   "source": [
    "file_loss_check(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to extract just import statements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cursor = db['git_repos_docs'].find({'file_extension': re.compile('py', re.IGNORECASE)}, \n",
    "                          {'_id': False, 'file_contents':1})\n",
    "\n",
    "#string = re.findall(r'import.*?/\\n' ,\"\" ,cursor['file_contents'])\n",
    "\n",
    "cur = cursor[1]['file_contents']\n",
    "a = re.sub(re.compile('\"\"\".*?\"\"\"',re.DOTALL) ,\"\" ,cur)\n",
    "a = re.sub(re.compile('#.*?\\n' ) ,' ' ,a)\n",
    "\n",
    "p = re.compile(\"import.*\\n\")\n",
    "c = re.findall(p, a)\n",
    "c\n",
    "\n",
    "p1 = re.compile(\"from .*\\n\")\n",
    "c1 = re.findall(p1, a)\n",
    "print(c)\n",
    "print(c1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to build graph network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cursor = db['git_repos_docs_backup'].find({'file_extension':'md'})\n",
    "\n",
    "cursor[6]['file_contents']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cursor = db['git_repos_contributors_backup'].find_one({'file_extension': re.compile('py', re.IGNORECASE)}, \n",
    "                          {'_id': False, 'repo_contributors':1})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
